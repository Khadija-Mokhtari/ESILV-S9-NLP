{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec149bf",
   "metadata": {},
   "source": [
    "# TP2, NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d34dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training a unigram part-of-speech tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5dfb1b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "tagger = UnigramTagger(train_sents)\n",
    "treebank.sents()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e7a2ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('board', 'NN'),\n",
       " ('as', 'IN'),\n",
       " ('a', 'DT'),\n",
       " ('nonexecutive', 'JJ'),\n",
       " ('director', 'NN'),\n",
       " ('Nov.', 'NNP'),\n",
       " ('29', 'CD'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger.tag(treebank.sents()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8021b9",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd24127e",
   "metadata": {},
   "source": [
    "## Practical work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de7896a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extraction of the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "56c18d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files are extracted\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "\n",
    "# Extract review_polarity.tar.gz\n",
    "with tarfile.open(r'C:\\Users\\Khadi\\OneDrive\\Documents\\ESILV\\A5\\NLP\\TP2_NLP\\review_polarity.tar.gz', 'r:gz') as tar:\n",
    "    tar.extractall()\n",
    "    print(\"Files are extracted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "492447fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1.2 Load and Pre-process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d501f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_reviews(path):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    for label in ['pos', 'neg']:\n",
    "        directory = f\"{path}/{label}\"\n",
    "        for filename in os.listdir(directory):\n",
    "            if filename.endswith('.txt'):\n",
    "                with open(f\"{directory}/{filename}\", 'r', encoding='utf-8') as file:\n",
    "                    reviews.append(file.read())\n",
    "                    labels.append(1 if label == 'pos' else 0)\n",
    "    return reviews, labels\n",
    "\n",
    "# Assuming the data is extracted to \"txt_sentoken\"\n",
    "reviews, labels = load_reviews('txt_sentoken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42e4d052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. POS Tagging and Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db6515be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.1 Train a Unigram POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9320bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import UnigramTagger\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "train_sents = treebank.tagged_sents()[:3000]\n",
    "tagger = UnigramTagger(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4aa339",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.2 POS-Tagging for Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ae57236a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_reviews = [tagger.tag(nltk.word_tokenize(review)) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ec29e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2.3 Sentiment Analysis with SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8be6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# def get_sentiment_score(tagged_review):\n",
    "#     score = 0\n",
    "#     for word, tag in tagged_review:\n",
    "#         wn_tag = get_wordnet_pos(tag)\n",
    "#         if wn_tag not in (wordnet.NOUN, wordnet.ADJ, wordnet.ADV, wordnet.VERB):\n",
    "#             continue\n",
    "#         lemma = wordnet.morphy(word, wn_tag)\n",
    "#         if not lemma:\n",
    "#             continue\n",
    "#         synsets = wordnet.synsets(lemma, pos=wn_tag)\n",
    "#         if not synsets:\n",
    "#             continue\n",
    "#         synset = synsets[0]\n",
    "#         swn_synset = swn.senti_synset(synset.name())\n",
    "#         score += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "#     return score\n",
    "\n",
    "def get_sentiment_score(tagged_review):\n",
    "    score = 0\n",
    "    for word, tag in tagged_review:\n",
    "        wn_tag = get_wordnet_pos(tag)\n",
    "        if wn_tag is None:\n",
    "            continue\n",
    "        lemma = wordnet.morphy(word, wn_tag)\n",
    "        if not lemma:\n",
    "            continue\n",
    "        synsets = wordnet.synsets(lemma, pos=wn_tag)\n",
    "        if not synsets:\n",
    "            continue\n",
    "        synset = synsets[0]\n",
    "        swn_synset = swn.senti_synset(synset.name())\n",
    "        print(f\"Word: {lemma}, Pos Score: {swn_synset.pos_score()}, Neg Score: {swn_synset.neg_score()}\")\n",
    "        score += swn_synset.pos_score() - swn_synset.neg_score()\n",
    "    return score\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag is None:\n",
    "        return None\n",
    "    \n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# scores = [get_sentiment_score(review) for review in tagged_reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7540452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d1e3b620",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_labels = ['Positive' if score > 0 else 'Negative' for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500bd5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Evaluation (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b85af06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(classified_labels))\n",
    "# print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "19a9ead6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1424f870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classified_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a506118e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khadi\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:226: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  score = y_true == y_pred\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(labels, classified_labels)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21492819",
   "metadata": {},
   "source": [
    "### Machine Learning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "36de29e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Example with Naive Bayes Classifier\n",
    "def train_and_evaluate_model(reviews, labels):\n",
    "    vectorizer = CountVectorizer()\n",
    "    features = vectorizer.fit_transform(reviews)\n",
    "\n",
    "    # Split the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3)\n",
    "\n",
    "    # Train the model\n",
    "    model = MultinomialNB()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Test the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Example usage:\n",
    "reviews = [\"This is a great movie\", \"This is a bad movie\"]\n",
    "labels = [\"Positive\", \"Negative\"]\n",
    "train_and_evaluate_model(reviews, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "afb7ca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Why do we get an accuracy of 0.0 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fe61fb07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1:\n",
      "Text: This is a great movie\n",
      "True label: Positive\n",
      "Predicted label: Positive\n",
      "Sentiment score: 7.125\n",
      "-------------\n",
      "Review 2:\n",
      "Text: This is a bad movie\n",
      "True label: Negative\n",
      "Predicted label: Positive\n",
      "Sentiment score: 7.375\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Print some diagnostics information\n",
    "for i, review in enumerate(reviews[:10]):  # Check the first 10 reviews\n",
    "    print(f\"Review {i+1}:\")\n",
    "    print(f\"Text: {review}\")\n",
    "    print(f\"True label: {labels[i]}\")\n",
    "    print(f\"Predicted label: {classified_labels[i]}\")\n",
    "    print(f\"Sentiment score: {scores[i]}\")\n",
    "    print(\"-------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744220f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7489bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6012c18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d02731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
